{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5Tu_WrQ2LBj"
      },
      "source": [
        "### Section 4.2.3 Ensemble Learning\n",
        "\n",
        "https://arxiv.org/pdf/1409.4842 - doing transformations on input data as proposed in given paper and following the methodolfy for training all models in ensemble"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rY2mEAwdWN_j"
      },
      "source": [
        "### Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoZe9cYP2Au9",
        "outputId": "cd636168-c376-4058-afe3-af08efd466a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import math\n",
        "import time\n",
        "from typing import Tuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# fix random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OvaB3E6WM5_"
      },
      "source": [
        "### Custom Implementation of Batch Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dON03oMl2AvB"
      },
      "outputs": [],
      "source": [
        "class CustomBatchNorm2d(nn.Module):\n",
        "    def __init__(self, num_features, eps=1e-5, momentum=0.1):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.momentum = momentum\n",
        "\n",
        "        self.gamma = nn.Parameter(torch.ones(num_features))\n",
        "        self.beta = nn.Parameter(torch.zeros(num_features))\n",
        "\n",
        "        self.register_buffer(\"running_mean\", torch.zeros(num_features))\n",
        "        self.register_buffer(\"running_var\", torch.ones(num_features))\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.training:\n",
        "            mean = x.mean(dim=(0, 2, 3))\n",
        "            var = x.var(dim=(0, 2, 3), unbiased=False)\n",
        "\n",
        "            self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * mean\n",
        "            self.running_var = (1 - self.momentum) * self.running_var + self.momentum * var\n",
        "        else:\n",
        "            mean = self.running_mean\n",
        "            var = self.running_var\n",
        "\n",
        "        x_hat = (x - mean[None, :, None, None]) / torch.sqrt(var[None, :, None, None] + self.eps)\n",
        "        out = self.gamma[None, :, None, None] * x_hat + self.beta[None, :, None, None]\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eUvZ8iwWYWp"
      },
      "source": [
        "### Defining Inception Block (as proposed in research paper)\n",
        "\n",
        "Please note that we have used only 2 inception blocks due to limitation of resource."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQF-Ruoi2AvC"
      },
      "outputs": [],
      "source": [
        "class ConvBNAct(nn.Module):\n",
        "    def __init__(self, in_c, out_c, k, s=1, p=0, use_bn=False, activation_fn=nn.ReLU):\n",
        "        super().__init__()\n",
        "        layers = [nn.Conv2d(in_c, out_c, k, s, p, bias=not use_bn)]\n",
        "        if use_bn:\n",
        "            layers.append(CustomBatchNorm2d(out_c))\n",
        "        layers.append(activation_fn()) # keeping it custom\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class InceptionBlock(nn.Module):\n",
        "    def __init__(self, in_c, use_bn=False, activation_fn=nn.ReLU):\n",
        "        super().__init__()\n",
        "\n",
        "        # shrink all widths\n",
        "        self.b1 = ConvBNAct(in_c, 8, 1, use_bn=use_bn, activation_fn=activation_fn)\n",
        "\n",
        "        self.b2 = nn.Sequential(\n",
        "            ConvBNAct(in_c, 8, 1, use_bn=use_bn, activation_fn=activation_fn),\n",
        "            ConvBNAct(8, 16, 3, p=1, use_bn=use_bn, activation_fn=activation_fn)\n",
        "        )\n",
        "\n",
        "        self.b3 = nn.Sequential(\n",
        "            ConvBNAct(in_c, 8, 1, use_bn=use_bn, activation_fn=activation_fn),\n",
        "            ConvBNAct(8, 16, 3, p=1, use_bn=use_bn, activation_fn=activation_fn),\n",
        "            ConvBNAct(16, 16, 3, p=1, use_bn=use_bn, activation_fn=activation_fn)\n",
        "        )\n",
        "\n",
        "        self.b4 = nn.Sequential(\n",
        "            nn.MaxPool2d(3, stride=1, padding=1),\n",
        "            ConvBNAct(in_c, 8, 1, use_bn=use_bn, activation_fn=activation_fn)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.cat([self.b1(x), self.b2(x), self.b3(x), self.b4(x)], dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oy1oQhD1Wg82"
      },
      "source": [
        "### TinyInception (Model defination for training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tc7lY8-72AvE"
      },
      "outputs": [],
      "source": [
        "class TinyInception(nn.Module):\n",
        "    def __init__(self, num_classes=10,\n",
        "                 use_bn=True,\n",
        "                 dropout_rate=0.05,\n",
        "                 increase_init=False,\n",
        "                 final_bn=False,\n",
        "                 activation_fn=nn.ReLU):\n",
        "        super().__init__()\n",
        "\n",
        "        self.stem = ConvBNAct(3, 16, 3, p=1, use_bn=use_bn, activation_fn=activation_fn)\n",
        "        self.inc1 = InceptionBlock(16, use_bn=use_bn, activation_fn=activation_fn)\n",
        "        self.inc2 = InceptionBlock(48, use_bn=use_bn, activation_fn=activation_fn)\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        # non-convolutional dropout used in BN-Inception paper\n",
        "        self.drop = nn.Dropout(dropout_rate)\n",
        "\n",
        "        # using batch norm in last layer\n",
        "        self.final_bn = nn.BatchNorm1d(48) if final_bn else nn.Identity()\n",
        "\n",
        "        self.fc = nn.Linear(48, num_classes)\n",
        "\n",
        "        # increase initial weights\n",
        "        if increase_init:\n",
        "            self._increase_initial_weights()\n",
        "\n",
        "    def _increase_initial_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.normal_(m.weight, mean=0, std=0.2)  # having larger variance\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        x = self.inc1(x)\n",
        "        x = self.inc2(x)\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        x = self.drop(x)\n",
        "        x = self.final_bn(x)\n",
        "\n",
        "        return self.fc(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cq-chJ1uWnoq"
      },
      "source": [
        "### Loading Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJJMng-R2gg8"
      },
      "source": [
        "#### Transformation on input data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPnHH4jq2j2R"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as T\n",
        "\n",
        "# performing random corp and photometric distortion on training data\n",
        "def cifar10_inception_style_transform():\n",
        "    transform = T.Compose([\n",
        "        # randomCrop\n",
        "        T.RandomCrop(32, padding=4),\n",
        "\n",
        "        # flipping image\n",
        "        T.RandomHorizontalFlip(),\n",
        "\n",
        "        # photometric distortions- but small as suggestion\n",
        "        T.ColorJitter(\n",
        "            brightness=0.2,\n",
        "            contrast=0.2,\n",
        "            saturation=0.2,\n",
        "            hue=0.05\n",
        "        ),\n",
        "\n",
        "        T.ToTensor(),\n",
        "\n",
        "        # Normalize\n",
        "        T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    return transform\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-r92MmcC2AvF"
      },
      "outputs": [],
      "source": [
        "def load_cifar_10():\n",
        "    train_transform = cifar10_inception_style_transform()\n",
        "\n",
        "    test_transform = T.Compose([\n",
        "        T.ToTensor(),\n",
        "        T.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
        "    ])\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(\n",
        "        root='./data', train=True, download=True,\n",
        "        transform=train_transform\n",
        "    )\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(\n",
        "        trainset, batch_size=64, shuffle=True, num_workers=4\n",
        "    )\n",
        "\n",
        "    testset = torchvision.datasets.CIFAR10(\n",
        "        root='./data', train=False, download=True,\n",
        "        transform=test_transform\n",
        "    )\n",
        "\n",
        "    testloader = torch.utils.data.DataLoader(\n",
        "        testset, batch_size=64, shuffle=False, num_workers=4\n",
        "    )\n",
        "\n",
        "    return trainloader, testloader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dIjb_RTWuzW"
      },
      "source": [
        "### Model Training function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOyMDe_52AvG"
      },
      "outputs": [],
      "source": [
        "def train_model(model, trainloader, valloader, epochs=30, lr=0.045,\n",
        "                resume=True):\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model = model.to(device)\n",
        "\n",
        "    opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    train_acc_list = []\n",
        "    val_acc_list = []\n",
        "    epos = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        correct = total = 0\n",
        "\n",
        "        for x, y in trainloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            opt.zero_grad()\n",
        "            out = model(x)\n",
        "            loss = criterion(out, y)\n",
        "\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            _, pred = out.max(1)\n",
        "            correct += pred.eq(y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "        train_acc = correct / total\n",
        "        train_acc_list.append(train_acc)\n",
        "        epos.append(epoch)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        correct = total = 0\n",
        "        with torch.no_grad():\n",
        "            for x, y in valloader:\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                out = model(x)\n",
        "                _, pred = out.max(1)\n",
        "                correct += pred.eq(y).sum().item()\n",
        "                total += y.size(0)\n",
        "\n",
        "        val_acc = correct / total\n",
        "        val_acc_list.append(val_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Train Acc={train_acc:.2f} | Val Acc={val_acc:.2f}\")\n",
        "\n",
        "\n",
        "    return train_acc_list, val_acc_list, epos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgycX5cjWzRj"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtKpt6bc2AvH",
        "outputId": "6e77f1a0-7a2e-48ad-b9a1-c872d639da85"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 48.0MB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "trainloader, valloader = load_cifar_10()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lh38sn4Q6jOr"
      },
      "source": [
        "## Define models for ensemble learning\n",
        "\n",
        "Done as per following description : Each was based on BN-x30, modified via some of the following: increased initial weights in the convolutional layers; using Dropout (with the Dropout probability of 5% or 10%, vs. 40%\n",
        "for the original Inception) and using non-convolutional, per-activation Batch Normalization with last hidden layers of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7jdIf24XeRV"
      },
      "outputs": [],
      "source": [
        "training_results = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPFpjIU569XP"
      },
      "outputs": [],
      "source": [
        "def build_ensemble_models():\n",
        "    models = []\n",
        "\n",
        "    configs = [\n",
        "        # dropout 5% - 10%\n",
        "        {\"dropout_rate\": 0.05, \"increase_init\": False, \"final_bn\": False},\n",
        "        {\"dropout_rate\": 0.10, \"increase_init\": False, \"final_bn\": False},\n",
        "\n",
        "        # increased weight init\n",
        "        {\"dropout_rate\": 0.05, \"increase_init\": True, \"final_bn\": False},\n",
        "        {\"dropout_rate\": 0.10, \"increase_init\": True, \"final_bn\": False},\n",
        "\n",
        "        # using batchNorm in the final linear layer\n",
        "        {\"dropout_rate\": 0.05, \"increase_init\": False, \"final_bn\": True},\n",
        "        {\"dropout_rate\": 0.10, \"increase_init\": False, \"final_bn\": True},\n",
        "    ]\n",
        "\n",
        "    for cfg in configs:\n",
        "        model = TinyInception(\n",
        "            num_classes=10,\n",
        "            use_bn=True,\n",
        "            dropout_rate=cfg[\"dropout_rate\"],\n",
        "            increase_init=cfg[\"increase_init\"],\n",
        "            final_bn=cfg[\"final_bn\"]\n",
        "        )\n",
        "        models.append({\"model\":model,\"config\":cfg})\n",
        "\n",
        "    return models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkgUovYL7SSS"
      },
      "outputs": [],
      "source": [
        "def ensemble_predict(models, x):\n",
        "    probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for model in models:\n",
        "            logits = model[\"model\"](x)\n",
        "            p = torch.softmax(logits, dim=1)\n",
        "            probs.append(p)\n",
        "\n",
        "    # arithmetic average (as per the paper)\n",
        "    return torch.mean(torch.stack(probs), dim=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfQptbgz7aCB"
      },
      "source": [
        "## Training each model independently now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZfc3_Rn8p1_"
      },
      "outputs": [],
      "source": [
        "models = build_ensemble_models()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hJPsxJSh9ipW",
        "outputId": "d726f0e0-e65b-4833-fcb3-ebb43f4cef69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dropout_rate': 0.05, 'increase_init': False, 'final_bn': False}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "models[0][\"config\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1tan5O2_uiy"
      },
      "source": [
        "#### Model - 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reT9rA6r2AvI",
        "outputId": "39385cd5-3f31-417d-c9f1-291962856c4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Train Acc=0.36 | Val Acc=0.44\n",
            "Epoch 2: Train Acc=0.50 | Val Acc=0.52\n",
            "Epoch 3: Train Acc=0.55 | Val Acc=0.49\n",
            "Epoch 4: Train Acc=0.58 | Val Acc=0.57\n",
            "Epoch 5: Train Acc=0.59 | Val Acc=0.53\n",
            "Epoch 6: Train Acc=0.60 | Val Acc=0.53\n",
            "Epoch 7: Train Acc=0.61 | Val Acc=0.60\n",
            "Epoch 8: Train Acc=0.62 | Val Acc=0.62\n",
            "Epoch 9: Train Acc=0.63 | Val Acc=0.62\n",
            "Epoch 10: Train Acc=0.64 | Val Acc=0.65\n",
            "Epoch 11: Train Acc=0.65 | Val Acc=0.67\n",
            "Epoch 12: Train Acc=0.65 | Val Acc=0.66\n",
            "Epoch 13: Train Acc=0.65 | Val Acc=0.68\n",
            "Epoch 14: Train Acc=0.65 | Val Acc=0.67\n",
            "Epoch 15: Train Acc=0.66 | Val Acc=0.67\n",
            "Epoch 16: Train Acc=0.66 | Val Acc=0.65\n",
            "Epoch 17: Train Acc=0.66 | Val Acc=0.66\n",
            "Epoch 18: Train Acc=0.67 | Val Acc=0.68\n",
            "Epoch 19: Train Acc=0.67 | Val Acc=0.69\n",
            "Epoch 20: Train Acc=0.67 | Val Acc=0.68\n",
            "Epoch 21: Train Acc=0.68 | Val Acc=0.69\n",
            "Epoch 22: Train Acc=0.68 | Val Acc=0.63\n",
            "Epoch 23: Train Acc=0.68 | Val Acc=0.65\n",
            "Epoch 24: Train Acc=0.68 | Val Acc=0.67\n",
            "Epoch 25: Train Acc=0.69 | Val Acc=0.69\n",
            "Epoch 26: Train Acc=0.69 | Val Acc=0.68\n",
            "Epoch 27: Train Acc=0.69 | Val Acc=0.71\n",
            "Epoch 28: Train Acc=0.69 | Val Acc=0.70\n",
            "Epoch 29: Train Acc=0.69 | Val Acc=0.71\n",
            "Epoch 30: Train Acc=0.69 | Val Acc=0.69\n"
          ]
        }
      ],
      "source": [
        "acc_train_0, acc_val_0, ep = train_model(models[0][\"model\"], trainloader, valloader,epochs=30,lr=0.045)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11563fdf",
        "outputId": "d83e2137-2bd6-45f0-8aaf-fc1ee06de75a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model 'model_0.pth' saved successfully.\n"
          ]
        }
      ],
      "source": [
        "torch.save(models[0][\"model\"].state_dict(), 'model_0.pth')\n",
        "print(\"Model 'model_0.pth' saved successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OPNCH-GoXv4f",
        "outputId": "6a0d89f6-e3f6-4f94-de44-957a1daeb7f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training result information appended: [{'model_config': {'dropout_rate': 0.05, 'increase_init': False, 'final_bn': False}, 'train_acc': [0.3596, 0.5016, 0.5503, 0.57606, 0.59178, 0.60388, 0.61448, 0.6223, 0.63086, 0.6366, 0.64596, 0.64786, 0.65202, 0.65424, 0.6608, 0.66348, 0.6646, 0.6714, 0.67212, 0.67368, 0.67572, 0.67894, 0.67914, 0.68196, 0.68674, 0.6867, 0.6878, 0.68814, 0.69244, 0.69424], 'val_acc': [0.4429, 0.5208, 0.4855, 0.5656, 0.5316, 0.5321, 0.6009, 0.6216, 0.6216, 0.6451, 0.6653, 0.6558, 0.6771, 0.6733, 0.6666, 0.6503, 0.6616, 0.6816, 0.6938, 0.6825, 0.6925, 0.6338, 0.6547, 0.6718, 0.6946, 0.683, 0.7078, 0.6954, 0.712, 0.693], 'epochs': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]}]\n"
          ]
        }
      ],
      "source": [
        "training_results.append({\n",
        "    \"model_config\": models[0][\"config\"],\n",
        "    \"train_acc\": acc_train_0,\n",
        "    \"val_acc\": acc_val_0,\n",
        "    \"epochs\": ep,\n",
        "})\n",
        "print(f\"Training result information appended: {training_results}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2bOqceN2AvK"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot([i+1 for i in ep], acc_val_0, label=\"Dropout 5% - LR:30x\")\n",
        "plt.title(\"Validation Accuracy vs Epoch (CIFAR-10)\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.savefig(\"model_dropout_0.png\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEUUiWJGYS8S"
      },
      "source": [
        "#### Model - 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngUCYNvn_63l",
        "outputId": "b833dca5-b3ec-4f2a-ab9e-919b0c28ff22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dropout_rate': 0.1, 'increase_init': False, 'final_bn': False}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "models[1][\"config\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcxktUhbDcxd"
      },
      "outputs": [],
      "source": [
        "trainloader, valloader = load_cifar_10()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d53J4zC2AvL",
        "outputId": "be39b865-781a-4eee-a4dd-a5de364fa62a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Train Acc=0.35 | Val Acc=0.43\n",
            "Epoch 2: Train Acc=0.48 | Val Acc=0.47\n",
            "Epoch 3: Train Acc=0.53 | Val Acc=0.48\n",
            "Epoch 4: Train Acc=0.56 | Val Acc=0.57\n",
            "Epoch 5: Train Acc=0.58 | Val Acc=0.56\n",
            "Epoch 6: Train Acc=0.59 | Val Acc=0.55\n",
            "Epoch 7: Train Acc=0.60 | Val Acc=0.63\n",
            "Epoch 8: Train Acc=0.61 | Val Acc=0.60\n",
            "Epoch 9: Train Acc=0.62 | Val Acc=0.65\n",
            "Epoch 10: Train Acc=0.63 | Val Acc=0.65\n",
            "Epoch 11: Train Acc=0.63 | Val Acc=0.66\n",
            "Epoch 12: Train Acc=0.63 | Val Acc=0.66\n",
            "Epoch 13: Train Acc=0.64 | Val Acc=0.65\n",
            "Epoch 14: Train Acc=0.64 | Val Acc=0.66\n",
            "Epoch 15: Train Acc=0.64 | Val Acc=0.65\n",
            "Epoch 16: Train Acc=0.65 | Val Acc=0.63\n",
            "Epoch 17: Train Acc=0.65 | Val Acc=0.67\n",
            "Epoch 18: Train Acc=0.66 | Val Acc=0.66\n",
            "Epoch 19: Train Acc=0.66 | Val Acc=0.68\n",
            "Epoch 20: Train Acc=0.66 | Val Acc=0.67\n",
            "Epoch 21: Train Acc=0.66 | Val Acc=0.69\n",
            "Epoch 22: Train Acc=0.66 | Val Acc=0.68\n",
            "Epoch 23: Train Acc=0.66 | Val Acc=0.69\n",
            "Epoch 24: Train Acc=0.67 | Val Acc=0.67\n",
            "Epoch 25: Train Acc=0.67 | Val Acc=0.68\n",
            "Epoch 26: Train Acc=0.67 | Val Acc=0.62\n",
            "Epoch 27: Train Acc=0.67 | Val Acc=0.69\n",
            "Epoch 28: Train Acc=0.67 | Val Acc=0.69\n",
            "Epoch 29: Train Acc=0.67 | Val Acc=0.69\n",
            "Epoch 30: Train Acc=0.67 | Val Acc=0.68\n"
          ]
        }
      ],
      "source": [
        "acc_train_1,acc_val_1,eps = train_model(models[1][\"model\"], trainloader, valloader,epochs=30,lr=0.045)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwUWBTfNYd7J",
        "outputId": "5357950d-916e-406b-9b2a-08e7b123182b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model 'model_1.pth' saved successfully.\n"
          ]
        }
      ],
      "source": [
        "torch.save(models[1][\"model\"].state_dict(), 'model_1.pth')\n",
        "print(\"Model 'model_1.pth' saved successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tsSsdOpVYorK",
        "outputId": "68a89634-d0c0-4bc6-99de-17e7dc4045fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training result information appended: [{'model_config': {'dropout_rate': 0.1, 'increase_init': False, 'final_bn': False}, 'train_acc': [0.34944, 0.47666, 0.5278, 0.5554, 0.57642, 0.58994, 0.60132, 0.60948, 0.61838, 0.6265, 0.62814, 0.63212, 0.63944, 0.64028, 0.64384, 0.64826, 0.6484, 0.65816, 0.65702, 0.65736, 0.66018, 0.66204, 0.66082, 0.66532, 0.66706, 0.66936, 0.6692, 0.67186, 0.6719, 0.67488], 'val_acc': [0.4292, 0.4748, 0.4783, 0.5671, 0.565, 0.5474, 0.6268, 0.5981, 0.6518, 0.651, 0.6575, 0.6648, 0.6517, 0.661, 0.6482, 0.6267, 0.6677, 0.6631, 0.6836, 0.6745, 0.6882, 0.6845, 0.6944, 0.672, 0.6848, 0.6229, 0.6928, 0.6926, 0.6885, 0.677], 'epochs': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]}]\n"
          ]
        }
      ],
      "source": [
        "training_results.append({\n",
        "    \"model_config\": models[1][\"config\"],\n",
        "    \"train_acc\": acc_train_1,\n",
        "    \"val_acc\": acc_val_1,\n",
        "    \"epochs\": eps,\n",
        "})\n",
        "print(f\"Training result information appended: {training_results}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGKclFeTYvl7"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot([i+1 for i in eps], acc_val_1, label=\"Dropout 10% - LR:30x\")\n",
        "plt.title(\"Validation Accuracy vs Epoch (CIFAR-10)\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.savefig(\"model_dropout_10.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7EgKzUGY6eP"
      },
      "source": [
        "#### Model 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIQ03RiVAtTY",
        "outputId": "71de165a-35bd-4651-cd4a-46c9ac181beb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dropout_rate': 0.05, 'increase_init': True, 'final_bn': False}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "models[2][\"config\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgQ7IfbjDfbY"
      },
      "outputs": [],
      "source": [
        "trainloader, valloader = load_cifar_10()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxPozVPaZHYB"
      },
      "outputs": [],
      "source": [
        "acc_train_2,acc_val_2,eps = train_model(models[2][\"model\"], trainloader, valloader,epochs=30,lr=0.045)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnN5kLPCZPdY"
      },
      "outputs": [],
      "source": [
        "torch.save(models[2][\"model\"].state_dict(), 'model_2.pth')\n",
        "print(\"Model 'model_2.pth' saved successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPE41_RjZTFd"
      },
      "outputs": [],
      "source": [
        "training_results.append({\n",
        "    \"model_config\": models[2][\"config\"],\n",
        "    \"train_acc\": acc_train_2,\n",
        "    \"val_acc\": acc_val_2,\n",
        "    \"epochs\": eps,\n",
        "})\n",
        "print(f\"Training result information appended: {training_results}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hs0lOGeeZcWE"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot([i+1 for i in eps], acc_val_2, label=\"Dropout 5% - LR:30x - Increase Init\")\n",
        "plt.title(\"Validation Accuracy vs Epoch (CIFAR-10)\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.savefig(\"model_dropout_5_increase_init.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxM5JYLeZrvo"
      },
      "source": [
        "#### Model 3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C79hyE0DBFZz"
      },
      "outputs": [],
      "source": [
        "models[3][\"config\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvFlMB0aDk3l"
      },
      "outputs": [],
      "source": [
        "trainloader, valloader = load_cifar_10()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMr1rPpbZ0gb"
      },
      "outputs": [],
      "source": [
        "acc_train_3,acc_val_3,eps = train_model(models[3][\"model\"], trainloader, valloader,epochs=30,lr=0.045)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBjyMtlDZ_0K"
      },
      "outputs": [],
      "source": [
        "torch.save(models[3][\"model\"].state_dict(), 'model_3.pth')\n",
        "print(\"Model 'model_3.pth' saved successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PZ_6k3qaF-j"
      },
      "outputs": [],
      "source": [
        "training_results.append({\n",
        "    \"model_config\": models[3][\"config\"],\n",
        "    \"train_acc\": acc_train_3,\n",
        "    \"val_acc\": acc_val_3,\n",
        "    \"epochs\": eps,\n",
        "})\n",
        "print(f\"Training result information appended: {training_results}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uun6OYnea9-6"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot([i+1 for i in eps], acc_val_3, label=\"Dropout 10% - LR:30x - Increase Init\")\n",
        "plt.title(\"Validation Accuracy vs Epoch (CIFAR-10)\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.savefig(\"model_dropout_10_increase_init.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ylrBTyZaPvV"
      },
      "source": [
        "#### Model 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyll69EOBVHV"
      },
      "outputs": [],
      "source": [
        "models[4][\"config\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFX7lZ6ZDoUy"
      },
      "outputs": [],
      "source": [
        "trainloader, valloader = load_cifar_10()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2il5L7JaVUz"
      },
      "outputs": [],
      "source": [
        "acc_train_4,acc_val_4,eps = train_model(models[4][\"model\"], trainloader, valloader,epochs=30,lr=0.045)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcWIRMkVdu2A"
      },
      "outputs": [],
      "source": [
        "torch.save(models[4][\"model\"].state_dict(), 'model_4.pth')\n",
        "print(\"Model 'model_4.pth' saved successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EubGOBrqdw_a"
      },
      "outputs": [],
      "source": [
        "training_results.append({\n",
        "    \"model_config\": models[4][\"config\"],\n",
        "    \"train_acc\": acc_train_4,\n",
        "    \"val_acc\": acc_val_4,\n",
        "    \"epochs\": eps,\n",
        "})\n",
        "print(f\"Training result information appended: {training_results}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEvI-u-Ed3b7"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot([i+1 for i in eps], acc_val_4, label=\"Dropout 5% - LR:30x - Final BN\")\n",
        "plt.title(\"Validation Accuracy vs Epoch (CIFAR-10)\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.savefig(\"model_dropout_5_final_bn.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiwxlF4yCBkc"
      },
      "source": [
        "#### Model 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkfxBr3fCDue"
      },
      "outputs": [],
      "source": [
        "models[5][\"config\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dP9exFDXDq4T"
      },
      "outputs": [],
      "source": [
        "trainloader, valloader = load_cifar_10()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klI-rNdZCDdc"
      },
      "outputs": [],
      "source": [
        "acc_train_5,acc_val_5,eps = train_model(models[5][\"model\"], trainloader, valloader,epochs=30,lr=0.045)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-I-zffYNCOPj"
      },
      "outputs": [],
      "source": [
        "torch.save(models[5][\"model\"].state_dict(), 'model_5.pth')\n",
        "print(\"Model 'model_5.pth' saved successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDADgsowCSXp"
      },
      "outputs": [],
      "source": [
        "training_results.append({\n",
        "    \"model_config\": models[5][\"config\"],\n",
        "    \"train_acc\": acc_train_5,\n",
        "    \"val_acc\": acc_val_5,\n",
        "    \"epochs\": eps,\n",
        "})\n",
        "print(f\"Training result information appended: {training_results}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKVPXTtECYBI"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot([i+1 for i in eps], acc_val_5, label=\"Dropout 10% - LR:30x - Final BN\")\n",
        "plt.title(\"Validation Accuracy vs Epoch (CIFAR-10)\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.savefig(\"model_dropout_10_final_bn.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxBjWyHoeLtc"
      },
      "source": [
        "### Saving results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ad3f301d"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Prepare the training results for JSON serialization by excluding model objects\n",
        "serializable_results = []\n",
        "for result in training_results:\n",
        "    serializable_result = {\n",
        "        \"train_acc\": result[\"train_acc\"],\n",
        "        \"val_acc\": result[\"val_acc\"],\n",
        "        \"epochs\": result[\"epochs\"],\n",
        "        \"description\": result[\"description\"]\n",
        "    }\n",
        "    serializable_results.append(serializable_result)\n",
        "\n",
        "# Save the serializable results to a JSON file\n",
        "with open('training_results.json', 'w') as f:\n",
        "    json.dump(serializable_results, f, indent=4)\n",
        "\n",
        "print(\"Training results saved to 'training_results.json' successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJi_5_TuQu8O"
      },
      "source": [
        "### Predicting results using the ensemble of models trained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcgTEgUmCbxZ"
      },
      "outputs": [],
      "source": [
        "def load_ensemble_models():\n",
        "    models = build_ensemble_models()  # recreates architecture with same configs\n",
        "\n",
        "    for i, item in enumerate(models):\n",
        "        if i!=2:\n",
        "            path = f\"model_{i}.pth\"\n",
        "            state_dict = torch.load(path, map_location=\"cpu\")\n",
        "            item[\"model\"].load_state_dict(state_dict)\n",
        "            item[\"model\"].eval()\n",
        "\n",
        "    return models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRB00zhYG8Qh"
      },
      "outputs": [],
      "source": [
        "def ensemble_predict(models, inputs):\n",
        "    logits_list = []\n",
        "    for item in models:\n",
        "        model = item[\"model\"]\n",
        "        with torch.no_grad():\n",
        "            logits = model(inputs)\n",
        "            logits_list.append(logits)\n",
        "\n",
        "    # average logits\n",
        "    avg_logits = torch.mean(torch.stack(logits_list), dim=0)\n",
        "    return avg_logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUMWAwVSG-FD"
      },
      "outputs": [],
      "source": [
        "def evaluate_ensemble(models, val_loader, device=\"cuda\"):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in val_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        avg_logits = ensemble_predict(models, inputs)\n",
        "        preds = avg_logits.argmax(dim=1)\n",
        "\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    return correct / total\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGbPfwzYG_m9",
        "outputId": "3d49c41b-c4b5-413e-819f-5b891609c09d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ensemble Validation Accuracy = 73.64%\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# load trained ensemble models\n",
        "models = load_ensemble_models()\n",
        "\n",
        "for item in models:\n",
        "    item[\"model\"].to(device)\n",
        "\n",
        "# compute accuracy using simple averaging\n",
        "acc = evaluate_ensemble(models, valloader, device)\n",
        "print(f\"Ensemble Validation Accuracy = {acc * 100:.2f}%\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 938448,
          "sourceId": 1590853,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31192,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
